import os
import torch
from torch.utils.data import DataLoader
from CYCLE_GAN.train  import train_network
from DIffusion_Model.VE_JP import VEJP_Diffusion, train_diffusion
from DIffusion_Model.dataloader import TrainData
from utils import save_checkpoint, load_checkpoint
from segmentation import calculate_metrics, multi_modality_ensemble, visualize_results, apply_segmentation
import config


def stage1_cyclegan():
    """Stage 1: Train CycleGAN for pseudo-paired generation."""
    print("Starting Stage 1: CycleGAN Training...")
    train_network()
    print("Stage 1 Complete!")


def stage2_diffusion():
    """Stage 2: Train VE-JP Diffusion Model."""
    print("Starting Stage 2: VE-JP Diffusion Training...")

    # Load pseudo-paired data generated by CycleGAN
    train_dataset = TrainData(root_dir=config.train_dir, transform=config.transforms)
    train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, num_workers=config.num_workers)

    # Define diffusion model parameters
    timesteps = 1000
    noise_schedule = torch.linspace(0.01, 0.1, timesteps).to(config.DEVICE)

    # Initialize VE-JP Diffusion model
    model = VEJP_Diffusion(noise_schedule=noise_schedule, input_channels=4).to(config.DEVICE)
    optimizer = torch.optim.Adam(model.parameters(), lr=config.learning_rate, betas=(0.5, 0.999))

    # Load checkpoint if available
    if config.load_model:
        load_checkpoint(config.CHECKPOINT_GEN_NORMAL, model, optimizer, config.learning_rate)

    # Train the diffusion model
    train_diffusion(model, train_loader, optimizer, noise_schedule, epochs=config.num_epochs, save_dir="output_images/")
    print("Stage 2 Complete!")


def stage3_segmentation():
    """Stage 3: Multi-Modality Ensemble and Segmentation."""
    print("Starting Stage 3: Multi-Modality Ensemble and Segmentation...")

    # Example modalities (replace with real data)
    modalities = [
        torch.randn(1, 256, 256),  # Flair
        torch.randn(1, 256, 256),  # T1w
        torch.randn(1, 256, 256),  # T1ce
        torch.randn(1, 256, 256)   # T2w
    ]
    weights = [0.4, 0.1, 0.2, 0.3]  # Example weights

    # Multi-Modality Ensemble
    ensemble_result = multi_modality_ensemble(modalities, weights)

    # Anomaly Detection and Segmentation
    original = modalities[0].numpy()  # Placeholder original image
    reconstructed = ensemble_result  # Replace with reconstructed output
    anomaly_map, mask = apply_segmentation(reconstructed, original)

    # Visualization
    visualize_results(original, reconstructed, anomaly_map, mask, epoch=1, save_dir="output_images/")
    print("Stage 3 Complete!")


def main():
    """Main workflow for integrating all stages."""
    # Run Stage 1: Train CycleGAN
    if config.run_stage1:
        stage1_cyclegan()

    # Run Stage 2: Train VE-JP Diffusion
    if config.run_stage2:
        stage2_diffusion()

    # Run Stage 3: Multi-Modality Ensemble and Segmentation
    if config.run_stage3:
        stage3_segmentation()


if __name__ == "__main__":
    main()
